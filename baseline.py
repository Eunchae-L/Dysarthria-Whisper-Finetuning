# -*- coding: utf-8 -*-
"""baseline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g8ATPGz6Kn_Vgy0Dws3offIaFvFryweR
"""

!pip install transformers
!pip install --upgrade transformers

!pip install -q datasets librosa evaluate jiwer gradio bitsandbytes==0.37 accelerate
!pip install -q git+https://github.com/huggingface/peft.git@main
!pip install torchaudio
!pip install --upgrade bitsandbytes
!pip install --upgrade peft

import torch

test_dysarthria_data = torch.load("test_dysarthria.pt")
test_nondysarthria_data = torch.load("test_non_dysarthria.pt")

from datasets import Dataset, DatasetDict

# 여러 스플릿으로 관리하기 위한 DatasetDict 생성
dataset_dict = DatasetDict({
    'dysarthria': Dataset.from_list(test_dysarthria_data),   # train split
    'non_dysarthria': Dataset.from_list(test_nondysarthria_data),  # validation split
})

from datasets import load_dataset
from transformers import WhisperForConditionalGeneration, WhisperProcessor, WhisperFeatureExtractor, WhisperTokenizer
import torch
from evaluate import load

model_name = "openai/whisper-small"
model = WhisperForConditionalGeneration.from_pretrained(model_name).to("cuda")

feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name)
tokenizer = WhisperTokenizer.from_pretrained(model_name, language="en", task="transcribe")
processor = WhisperProcessor.from_pretrained(model_name, language="en", task="transcribe")

def prepare_dataset(batch):
    # load and resample audio data from 48 to 16kHz
    audio = batch["audio"]

    # compute log-Mel input features from input audio array
    batch["input_features"] = feature_extractor(audio["array"], sampling_rate=audio["sampling_rate"]).input_features[0]

    # encode target text to label ids
    batch["labels"] = tokenizer(batch["sentence"]).input_ids
    return batch

data = dataset_dict.map(prepare_dataset, remove_columns=dataset_dict.column_names["dysarthria"])

data

import torch

from dataclasses import dataclass
from typing import Any, Dict, List, Union


@dataclass
class DataCollatorSpeechSeq2SeqWithPadding:
    processor: Any

    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:
        # split inputs and labels since they have to be of different lengths and need different padding methods
        # first treat the audio inputs by simply returning torch tensors
        input_features = [{"input_features": feature["input_features"]} for feature in features]
        batch = self.processor.feature_extractor.pad(input_features, return_tensors="pt")

        # get the tokenized label sequences
        label_features = [{"input_ids": feature["labels"]} for feature in features]
        # pad the labels to max length
        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors="pt")

        # replace padding with -100 to ignore loss correctly
        labels = labels_batch["input_ids"].masked_fill(labels_batch.attention_mask.ne(1), -100)

        # if bos token is appended in previous tokenization step,
        # cut bos token here as it's append later anyways
        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():
            labels = labels[:, 1:]

        batch["labels"] = labels

        return batch

data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)

"""### Dysarthria Test"""

import evaluate

metric = evaluate.load("wer")

import gc
import numpy as np
from tqdm import tqdm
from torch.utils.data import DataLoader
from transformers.models.whisper.english_normalizer import BasicTextNormalizer

# 커스텀 WER 계산 함수
def custom_wer(reference, hypothesis):
    """
    긴 예측 오류 또는 빈 예측 오류를 WER=1로 설정.
    """
    if not hypothesis or len(hypothesis.split()) > 2 * len(reference.split()):
        return 1.0  # WER = 1로 처리
    else:
        return metric.compute(predictions=[hypothesis], references=[reference])

# 데이터 로더 및 설정
dysarthria_data = DataLoader(data["dysarthria"], batch_size=8, collate_fn=data_collator)
forced_decoder_ids = processor.get_decoder_prompt_ids(language="en", task="transcribe")
normalizer = BasicTextNormalizer()

# 평가 결과 저장 변수
predictions = []
references = []
normalized_predictions = []
normalized_references = []

model.eval()
for step, batch in enumerate(tqdm(dysarthria_data)):
    with torch.cuda.amp.autocast():
        with torch.no_grad():
            # 예측 생성
            generated_tokens = (
                model.generate(
                    input_features=batch["input_features"].to("cuda"),
                    forced_decoder_ids=forced_decoder_ids,
                    max_new_tokens=255,
                )
                .cpu()
                .numpy()
            )
            # 라벨 처리
            labels = batch["labels"].cpu().numpy()
            labels = np.where(labels != -100, labels, processor.tokenizer.pad_token_id)
            decoded_preds = processor.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
            decoded_labels = processor.tokenizer.batch_decode(labels, skip_special_tokens=True)

            # 결과 저장
            predictions.extend(decoded_preds)
            references.extend(decoded_labels)
            normalized_predictions.extend([normalizer(pred).strip() for pred in decoded_preds])
            normalized_references.extend([normalizer(label).strip() for label in decoded_labels])

        # 메모리 정리
        del generated_tokens, labels, batch
    gc.collect()

# 커스텀 WER 계산
wer_values = [custom_wer(ref, pred) for ref, pred in zip(references, predictions)]
normalized_wer_values = [custom_wer(ref, pred) for ref, pred in zip(normalized_references, normalized_predictions)]

# 평균 WER 계산
wer = 100 * np.mean(wer_values)
normalized_wer = 100 * np.mean(normalized_wer_values)

eval_metrics = {"eval/wer": wer, "eval/normalized_wer": normalized_wer}

# 결과 출력
print(f"{wer=} and {normalized_wer=}")
print(eval_metrics)

for idx, (pred, ref) in enumerate(zip(predictions, references)):
    print(f"Index {idx}:\nPrediction: {pred}\nReference: {ref}\n")

def compare_lists(predictions, references):
    # Initialize counters
    exact_matches = 0
    mismatches = 0

    for pred, ref in zip(predictions, references):
        # Remove spaces for comparison
        pred_clean = pred.replace(" ", "")
        ref_clean = ref.replace(" ", "")

        if pred_clean == ref_clean:
            exact_matches += 1
        else:
            mismatches += 1

    return exact_matches, mismatches


# Compare the lists and get results
exact_matches, mismatches = compare_lists(predictions, references)

# Print the results
print(f"Exact Matches: {exact_matches}")
print(f"Mismatches: {mismatches}")

# 보조 지표 계산
from jiwer import wer as jiwer_wer, cer as jiwer_cer
jiwer_score = jiwer_wer(references, predictions) * 100
cer_score = jiwer_cer(references, predictions) * 100

print(f"JIWER WER: {jiwer_score:.2f}%, JIWER CER: {cer_score:.2f}%")

"""### Non-Dysarthria test"""

import gc
import numpy as np
from tqdm import tqdm
from torch.utils.data import DataLoader
from transformers.models.whisper.english_normalizer import BasicTextNormalizer

# 커스텀 WER 계산 함수
def custom_wer(reference, hypothesis):
    """
    긴 예측 오류 또는 빈 예측 오류를 WER=1로 설정.
    """
    if not hypothesis or len(hypothesis.split()) > 2 * len(reference.split()):
        return 1.0  # WER = 1로 처리
    else:
        return metric.compute(predictions=[hypothesis], references=[reference])

# 데이터 로더 및 설정
non_dysarthria_data = DataLoader(data["non_dysarthria"], batch_size=8, collate_fn=data_collator)
forced_decoder_ids = processor.get_decoder_prompt_ids(language="en", task="transcribe")
normalizer = BasicTextNormalizer()

# 평가 결과 저장 변수
predictions = []
references = []
normalized_predictions = []
normalized_references = []

model.eval()
for step, batch in enumerate(tqdm(non_dysarthria_data)):
    with torch.cuda.amp.autocast():
        with torch.no_grad():
            # 예측 생성
            generated_tokens = (
                model.generate(
                    input_features=batch["input_features"].to("cuda"),
                    forced_decoder_ids=forced_decoder_ids,
                    max_new_tokens=255,
                )
                .cpu()
                .numpy()
            )
            # 라벨 처리
            labels = batch["labels"].cpu().numpy()
            labels = np.where(labels != -100, labels, processor.tokenizer.pad_token_id)
            decoded_preds = processor.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
            decoded_labels = processor.tokenizer.batch_decode(labels, skip_special_tokens=True)

            # 결과 저장
            predictions.extend(decoded_preds)
            references.extend(decoded_labels)
            normalized_predictions.extend([normalizer(pred).strip() for pred in decoded_preds])
            normalized_references.extend([normalizer(label).strip() for label in decoded_labels])

        # 메모리 정리
        del generated_tokens, labels, batch
    gc.collect()

# 커스텀 WER 계산
wer_values = [custom_wer(ref, pred) for ref, pred in zip(references, predictions)]
normalized_wer_values = [custom_wer(ref, pred) for ref, pred in zip(normalized_references, normalized_predictions)]

# 평균 WER 계산
wer = 100 * np.mean(wer_values)
normalized_wer = 100 * np.mean(normalized_wer_values)

eval_metrics = {"eval/wer": wer, "eval/normalized_wer": normalized_wer}

# 결과 출력
print(f"{wer=} and {normalized_wer=}")
print(eval_metrics)

for idx, (pred, ref) in enumerate(zip(predictions, references)):
    print(f"Index {idx}:\nPrediction: {pred}\nReference: {ref}\n")

def compare_lists(predictions, references):
    # Initialize counters
    exact_matches = 0
    mismatches = 0

    for pred, ref in zip(predictions, references):
        # Remove spaces for comparison
        pred_clean = pred.replace(" ", "")
        ref_clean = ref.replace(" ", "")

        if pred_clean == ref_clean:
            exact_matches += 1
        else:
            mismatches += 1

    return exact_matches, mismatches


# Compare the lists and get results
exact_matches, mismatches = compare_lists(predictions, references)

# Print the results
print(f"Exact Matches: {exact_matches}")
print(f"Mismatches: {mismatches}")

# 보조 지표 계산
from jiwer import wer as jiwer_wer, cer as jiwer_cer
jiwer_score = jiwer_wer(references, predictions) * 100
cer_score = jiwer_cer(references, predictions) * 100

print(f"JIWER WER: {jiwer_score:.2f}%, JIWER CER: {cer_score:.2f}%")